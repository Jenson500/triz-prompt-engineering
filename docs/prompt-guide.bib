@online{debnath2025,
  title = {A {{Comprehensive Survey}} of {{Prompt Engineering Techniques}} in {{Large Language Models}}},
  author = {Debnath, Tonmoy and Siddiky, Md Nurul Absar and Rahman, Muhammad Enayetur and Das, Prosenjit and Guha, Antu Kumar},
  date = {2025-03-08},
  eprinttype = {TechRxiv},
  doi = {10.36227/techrxiv.174140719.96375390/v1},
  url = {https://www.techrxiv.org/users/898487/articles/1274333-a-comprehensive-survey-of-prompt-engineering-techniques-in-large-language-models},
  pubstate = {prepublished}
}

@online{park2023,
  title = {Generative {{Agents}}: {{Interactive Simulacra}} of {{Human Behavior}}},
  shorttitle = {Generative {{Agents}}},
  author = {Park, Joon Sung and O'Brien, Joseph C. and Cai, Carrie J. and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
  date = {2023-08-06},
  eprint = {2304.03442},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.03442},
  url = {http://arxiv.org/abs/2304.03442},
  abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents--computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture--observation, planning, and reflection--each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning},
  file = {C\:\\Users\\jens\\Zotero\\storage\\HBJBLMF9\\Park et al. - 2023 - Generative Agents Interactive Simulacra of Human Behavior.pdf;C\:\\Users\\jens\\Zotero\\storage\\6GUAUWYU\\2304.html}
}

@online{wei2023,
  title = {Chain-of-{{Thought Prompting Elicits Reasoning}} in {{Large Language Models}}},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  date = {2023-01-10},
  eprint = {2201.11903},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2201.11903},
  url = {http://arxiv.org/abs/2201.11903},
  abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\jens\\Zotero\\storage\\SESG82F2\\Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf;C\:\\Users\\jens\\Zotero\\storage\\6ZLMVNRG\\2201.html}
}

@online{zotero-item-1637,
  title = {Text Generation and Prompting - {{OpenAI API}}},
  url = {https://platform.openai.com/docs/guides/text?api-mode=responses},
  urldate = {2025-04-14},
  abstract = {Learn how to use the OpenAI API to generate text from a prompt. Learn about message types and available text formats like JSON and Structured Outputs.},
  langid = {english},
  file = {C:\Users\jens\Zotero\storage\J5I7D92S\text.html}
}
